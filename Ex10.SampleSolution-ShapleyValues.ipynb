{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1a3793-52a2-476d-9636-ae1f7a56b92d",
   "metadata": {},
   "source": [
    "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float:right;\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f77d1c-659e-4875-af10-69e1eb279373",
   "metadata": {},
   "source": [
    "# Musterl√∂sung / Sample solution \n",
    "## 10th exercise: <font color=\"#C70039\">Interpretable Machine Learning with Shapley Values for image classification</font>\n",
    "* Course: AML\n",
    "* Lecturer: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Author of notebook: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Date:   04.08.2025\n",
    "\n",
    "---------------------------------\n",
    "\n",
    "### <font color=\"ce33ff\">DESCRIPTION</font>:\n",
    "This is one implementation example to demo XAI for image classification using the inbuild cifar-10 data set, that you have come across with in exercise 8 already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64db0bc-ad21-4a46-9ff3-55e1e6e14bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739bcc4-4ab5-4925-937f-513d42ea1719",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "### load build-in dataset and preprocess\n",
    "Take the cifar-10 data set from exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915d6a8-d74f-45ce-81e9-6c9df0c9c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Use original 32x32 images\n",
    "x_train_processed = preprocess_input(np.array(x_train).astype(np.float32))\n",
    "x_test_processed = preprocess_input(np.array(x_test).astype(np.float32))\n",
    "\n",
    "# Reshape images for KernelExplainer (flatten pixels - see below)\n",
    "# KernelExplainer expects 1 or 2 dimensions. We'll reshape to (samples, num_features)\n",
    "num_test_samples = x_test_processed[:5].shape[0]\n",
    "flattened_test_images = x_test_processed[:5].reshape(num_test_samples, -1)\n",
    "\n",
    "num_train_samples = x_train_processed[:50].shape[0]\n",
    "flattened_train_images = x_train_processed[:50].reshape(num_train_samples, -1)\n",
    "\n",
    "# Explicitly convert background data to numpy array with float32 dtype\n",
    "flattened_train_images = np.array(flattened_train_images).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2615657-0d50-4831-b051-b81205c7dc7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modeling\n",
    "### Use a pretrained Model (here MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62dec5c-d1e1-41d4-824e-a1c3e57aaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using include_top=False to remove the classification layer, as we have 10 classes in CIFAR-10\n",
    "# Adjusted input_shape to 32x32\n",
    "'''Note: Using imagenet weights on 32x32 input might not be ideal since it was trained on much larger imnages'''\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Add a new classification layer for CIFAR-10\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Wrap the model's predict function for KernelExplainer\n",
    "# This function needs to accept the flattened input and reshape it back for the model\n",
    "def predict_fn_for_kernel(flattened_images):\n",
    "    # Reshape flattened images back to original shape for prediction\n",
    "    original_shape = (-1, 32, 32, 3)\n",
    "    images = flattened_images.reshape(original_shape)\n",
    "    return model.predict(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf643f-f085-41d7-b343-a3fe01cecd57",
   "metadata": {},
   "source": [
    "## Initialize the KernelExplainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55873cc-9859-4018-90d5-7ba55f1d797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel explainer works with the model's predict function\n",
    "# It requires a background dataset in the flattened format\n",
    "# Using a smaller subset for demonstration due to memory constraints\n",
    "explainer = shap.KernelExplainer(predict_fn_for_kernel, flattened_train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e178e45e-ae65-4f10-9ba8-cfa8b5c99003",
   "metadata": {},
   "source": [
    "## Calculate Shapley-values for test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317d932-40d8-4947-9453-1062c7520da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a smaller subset for demonstration\n",
    "# nsamples can be increased for better accuracy, but increases computation time\n",
    "shap_values = explainer.shap_values(flattened_test_images, nsamples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0a09f-559a-416c-9928-594744efa1e1",
   "metadata": {},
   "source": [
    "## Visualization of an explanation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21886eb4-227f-44c6-87a6-60d83b5a5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KernelExplainer's shap_values output format can vary.\n",
    "# For multi-output models, it's often a list of arrays.\n",
    "# We'll reshape the shap values back to image shape for plotting.\n",
    "# The second argument to image_plot should be the original images.\n",
    "# shap_values is a list, each element is a shapley value array for a class, shape (num_samples, num_features)\n",
    "# We need to reshape each of these back to image shape (num_samples, height, width, channels)\n",
    "shap_values_reshaped = [\n",
    "    s.reshape((-1, 32, 32, 3)) for s in shap_values\n",
    "]\n",
    "\n",
    "# We'll plot the shap values for the first class (index 0).\n",
    "# The second argument to image_plot should be the original images.\n",
    "shap.image_plot(shap_values_reshaped[0], -x_test_processed[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
