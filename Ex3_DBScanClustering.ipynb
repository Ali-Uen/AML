{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c6818b",
   "metadata": {
    "id": "f7c6818b"
   },
   "source": [
    "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float:right;\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58702112",
   "metadata": {
    "id": "58702112"
   },
   "source": [
    "# 3rd exercise: <font color=\"#C70039\">Do DBScan clustering for anomaly detection</font>\n",
    "* Course: AML\n",
    "* Lecturer: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Author of notebook: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Date:   10.11.2023\n",
    "* Student: Ali Ãœnal\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/DBSCAN-Illustration.svg/400px-DBSCAN-Illustration.svg.png\" style=\"float: center;\" width=\"450\">\n",
    "\n",
    "---------------------------------\n",
    "**GENERAL NOTE 1**:\n",
    "Please make sure you are reading the entire notebook, since it contains a lot of information on your tasks (e.g. regarding the set of certain paramaters or a specific computational trick), and the written mark downs as well as comments contain a lot of information on how things work together as a whole.\n",
    "\n",
    "**GENERAL NOTE 2**:\n",
    "* Please, when commenting source code, just use English language only.\n",
    "* When describing an observation please use English language, too\n",
    "* This applies to all exercises throughout this course.  \n",
    "\n",
    "---------------------\n",
    "\n",
    "### <font color=\"ce33ff\">DESCRIPTION</font>:\n",
    "This notebook allows you for using the DBScan clustering algorithm for anomaly detection.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### <font color=\"FFC300\">TASKS</font>:\n",
    "The tasks that you need to work on within this notebook are always indicated below as bullet points.\n",
    "If a task is more challenging and consists of several steps, this is indicated as well.\n",
    "Make sure you have worked down the task list and commented your doings.\n",
    "This should be done by using markdown.<br>\n",
    "<font color=red>Make sure you don't forget to specify your name and your matriculation number in the notebook.</font>\n",
    "\n",
    "**YOUR TASKS in this exercise are as follows**:\n",
    "1. import the notebook to Google Colab or use your local machine.\n",
    "2. make sure you specified you name and your matriculation number in the header below my name and date.\n",
    "    * set the date too and remove mine.\n",
    "3. read the entire notebook carefully\n",
    "    * add comments whereever you feel it necessary for better understanding\n",
    "    * run the notebook for the first time.\n",
    "4. take the three data sets from exercize 1 and cluster them\n",
    "5. read the following <a href=\"https://stats.stackexchange.com/questions/88872/a-routine-to-choose-eps-and-minpts-for-dbscan\">article</a> for getting help estimating eps and minPts\n",
    "    * https://stats.stackexchange.com/questions/88872/a-routine-to-choose-eps-and-minpts-for-dbscan\n",
    "6. describe your findings and interpret the results\n",
    "-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522a8e3c",
   "metadata": {
    "id": "522a8e3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import lognorm\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Q3B7M97grUYa",
   "metadata": {
    "id": "Q3B7M97grUYa"
   },
   "outputs": [],
   "source": [
    "# Load normalized Data for the first two Datasets\n",
    "df_firstDataset = pd.read_csv(\"SOCR-HeightWeight.csv\")['Height(Inches)'].values.reshape(-1, 1)\n",
    "df_secondDataset = pd.read_csv(\"SOCR-HeightWeight.csv\")['Weight(Pounds)'].values.reshape(-1, 1)\n",
    "\n",
    "# Load not normalized Data for last Dataset\n",
    "df_thirdDataset = pd.read_csv(\"incomeUS.csv\")['Age'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641d0d0",
   "metadata": {
    "id": "0641d0d0"
   },
   "source": [
    "The output of the below code is 94. This is the total number of noisy points. SKLearn labels the noisy points as (-1). The downside with this method is that the higher the dimension, the less accurate it becomes. You also need to make a few assumptions like estimating the right value for eps which can be challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "VO-4-KabrQYx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VO-4-KabrQYx",
    "outputId": "392fa681-86c6-47e4-c52b-acb1cea02f71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "# using these parameters after testing similar results where achived as in exercise 1, where 69 outliers where found\n",
    "# finding eps was hard but we went with trial and error aswell as trying to find the knee, as described in the stakeoverflow post, linked in the notebook\n",
    "# the attemps at finding the knee were deleted afterwards\n",
    "minPts = 3\n",
    "eps = 0.0179\n",
    "\n",
    "outlier_detection = DBSCAN(min_samples = minPts, eps = eps)\n",
    "\n",
    "clusters = outlier_detection.fit_predict(df_firstDataset)\n",
    "\n",
    "list(clusters).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "kbHROfaprQwf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kbHROfaprQwf",
    "outputId": "f3dc0876-a715-4fb1-8749-fdb9542d1f52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "# using these parameters after testing similar results where achived as in exercise 1, where 51 outliers where found\n",
    "minPts = 3\n",
    "eps = 0.079\n",
    "\n",
    "outlier_detection = DBSCAN(min_samples = minPts, eps = eps)\n",
    "\n",
    "clusters = outlier_detection.fit_predict(df_secondDataset)\n",
    "\n",
    "list(clusters).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb98bcc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb98bcc3",
    "outputId": "38c8a3cf-9eac-4d35-ac12-026d08508b23",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "# even when we changed eps the result didnt change, only two outlier where always found. Which is strange since in exercise 1, 129 outliers where found\n",
    "# maybe this could be because the data set isn't normalized\n",
    "# onyl changing the minPts had an effect on the results\n",
    "# the goal was to hit the same ballpark as the number of outliers in exercise 1, so 25 minPts were chosen at the end as the hyperparameter\n",
    "minPts = 25\n",
    "eps = 0.01\n",
    "\n",
    "outlier_detection = DBSCAN(min_samples = minPts, eps = eps)\n",
    "\n",
    "clusters = outlier_detection.fit_predict(df_thirdDataset)\n",
    "\n",
    "list(clusters).count(-1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
